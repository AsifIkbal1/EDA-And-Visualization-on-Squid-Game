{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<br>\n<br>\n<h2 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color:#1DA1F2 ; color :#FFFFFF; border-radius: 5px 5px; padding:10px;text-align:center; font-weight: bold\">Exploratory Data Analysis And Visualization on Squid Game Tweets</h2> \n<br> \n<br>\n\n<div class=\"Column\">\n  <div class=\"row\">\n    <img src=\"https://i.postimg.cc/HxhJ902h/60f5172816321e9428ac1ede-twitter.gif\" alt=\"Snow\" style=\"width:100%\">\n  </div>","metadata":{"execution":{"iopub.status.busy":"2022-06-11T14:30:45.205332Z","iopub.execute_input":"2022-06-11T14:30:45.205683Z","iopub.status.idle":"2022-06-11T14:30:45.21191Z","shell.execute_reply.started":"2022-06-11T14:30:45.205654Z","shell.execute_reply":"2022-06-11T14:30:45.211091Z"}}},{"cell_type":"markdown","source":"# **Introduction**\n\n**Squid Game (Korean: 오징어 게임; RR: Ojing-eo Geim) is a South Korean survival drama television series created by Hwang Dong-hyuk for Netflix.Its cast includes Lee Jung-jae, Park Hae-soo, Wi Ha-joon, HoYeon Jung, O Yeong-su, Heo Sung-tae, Anupam Tripathi, and Kim Joo-ryoung.**\n\n**The series revolves around a contest where 456 players, all of whom are in deep financial debt, risk their lives to play a series of deadly children's games for the chance to win a ₩45.6 billion (US$38 million, €33 million, or GB£29 million as of broadcast) prize. The title of the series draws from a similarly named Korean children's game.**","metadata":{"execution":{"iopub.status.busy":"2022-06-11T14:31:14.715185Z","iopub.execute_input":"2022-06-11T14:31:14.715561Z","iopub.status.idle":"2022-06-11T14:31:14.724508Z","shell.execute_reply.started":"2022-06-11T14:31:14.71552Z","shell.execute_reply":"2022-06-11T14:31:14.723373Z"}}},{"cell_type":"markdown","source":"<div class=\"Column\">\n  <div class=\"row\">\n    <img src=\"https://media.npr.org/assets/img/2021/10/15/squidgame_unit_101_577_wide-feafa98c140a6d814d3a600a52f75535bf1a2df4-s900-c85.webp\" alt=\"Snow\" style=\"width:100%\">\n  </div>","metadata":{}},{"cell_type":"markdown","source":"# **Importing the necessary libraries**:","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nimport itertools\n\n#plots\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nfrom plotly.colors import n_colors\nfrom plotly.subplots import make_subplots\n\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nfrom sklearn.feature_extraction.text import CountVectorizer\n\nfrom nltk.sentiment import SentimentIntensityAnalyzer\nfrom textblob import TextBlob\n\nfrom PIL import Image\nfrom nltk.corpus import stopwords\nstop=set(stopwords.words('english'))\nfrom nltk.util import ngrams\nfrom textblob import TextBlob\n%matplotlib inline \nimport missingno as mno\n\nimport re\nfrom collections import Counter\n\nimport nltk\nfrom nltk.corpus import stopwords\n\nimport requests\nimport json\n\nimport seaborn as sns\nsns.set(rc={'figure.figsize':(11.7,8.27)})\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path\n              .join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2022-06-27T19:49:24.57082Z","iopub.execute_input":"2022-06-27T19:49:24.571435Z","iopub.status.idle":"2022-06-27T19:49:29.139586Z","shell.execute_reply.started":"2022-06-27T19:49:24.571284Z","shell.execute_reply":"2022-06-27T19:49:29.138419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Loading Dataset**","metadata":{}},{"cell_type":"code","source":"twitter_data = pd.read_csv(\"../input/squid-game-netflix-twitter-data/tweets_v8.csv\")\n","metadata":{"execution":{"iopub.status.busy":"2022-06-27T19:49:29.141472Z","iopub.execute_input":"2022-06-27T19:49:29.141858Z","iopub.status.idle":"2022-06-27T19:49:30.455592Z","shell.execute_reply.started":"2022-06-27T19:49:29.141822Z","shell.execute_reply":"2022-06-27T19:49:30.454135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Let's take a quick overview of how the data looks!**:","metadata":{}},{"cell_type":"code","source":"# Examining Data\ntwitter_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-27T19:49:30.99574Z","iopub.execute_input":"2022-06-27T19:49:30.997185Z","iopub.status.idle":"2022-06-27T19:49:31.02993Z","shell.execute_reply.started":"2022-06-27T19:49:30.997125Z","shell.execute_reply":"2022-06-27T19:49:31.028596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Examining Data\ntwitter_data.tail()","metadata":{"execution":{"iopub.status.busy":"2022-06-27T19:49:31.669922Z","iopub.execute_input":"2022-06-27T19:49:31.671349Z","iopub.status.idle":"2022-06-27T19:49:31.690084Z","shell.execute_reply.started":"2022-06-27T19:49:31.671296Z","shell.execute_reply":"2022-06-27T19:49:31.689057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"In this dataset there are {} rows and {} columns in the dataset.\".format(twitter_data.shape[0],twitter_data.shape[1]))","metadata":{"execution":{"iopub.status.busy":"2022-06-27T19:49:32.78581Z","iopub.execute_input":"2022-06-27T19:49:32.786801Z","iopub.status.idle":"2022-06-27T19:49:32.792868Z","shell.execute_reply.started":"2022-06-27T19:49:32.786742Z","shell.execute_reply":"2022-06-27T19:49:32.791866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Examining statistics\ntwitter_data.describe()","metadata":{"execution":{"iopub.status.busy":"2022-06-27T19:49:33.407829Z","iopub.execute_input":"2022-06-27T19:49:33.408331Z","iopub.status.idle":"2022-06-27T19:49:33.466497Z","shell.execute_reply.started":"2022-06-27T19:49:33.408292Z","shell.execute_reply":"2022-06-27T19:49:33.465339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#let's get some information about the data types of our dataset by executing the code binfo()\ntwitter_data.info()","metadata":{"execution":{"iopub.status.busy":"2022-06-27T19:49:34.286286Z","iopub.execute_input":"2022-06-27T19:49:34.286736Z","iopub.status.idle":"2022-06-27T19:49:34.351589Z","shell.execute_reply.started":"2022-06-27T19:49:34.286703Z","shell.execute_reply":"2022-06-27T19:49:34.350516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##The below box plot also shows how the values are distributed for both int64 and bool variable type\nsns.boxplot(data=twitter_data, orient=\"h\", palette=\"Set2\")","metadata":{"execution":{"iopub.status.busy":"2022-06-27T19:49:35.237997Z","iopub.execute_input":"2022-06-27T19:49:35.238501Z","iopub.status.idle":"2022-06-27T19:49:35.741293Z","shell.execute_reply.started":"2022-06-27T19:49:35.238457Z","shell.execute_reply":"2022-06-27T19:49:35.73965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Missing Values:**","metadata":{}},{"cell_type":"code","source":"#Let's find out about the missing values in the dataset by executing the code below:\nmno.matrix(twitter_data)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T19:49:38.729078Z","iopub.execute_input":"2022-06-27T19:49:38.729569Z","iopub.status.idle":"2022-06-27T19:49:39.561017Z","shell.execute_reply.started":"2022-06-27T19:49:38.729534Z","shell.execute_reply":"2022-06-27T19:49:39.559507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"missed = pd.DataFrame()\nmissed['column'] = twitter_data.columns\n\nmissed['percent'] = [round(100* twitter_data[col].isnull().sum() / len(twitter_data), 2) for col in twitter_data.columns]\nmissed = missed.sort_values('percent',ascending=False)\nmissed = missed[missed['percent']>0]\n\nfig = sns.barplot(\n    x=missed['percent'], \n    y=missed[\"column\"], \n    orientation='horizontal'\n).set_title('Missed values percent for every column')","metadata":{"execution":{"iopub.status.busy":"2022-06-27T19:49:40.626807Z","iopub.execute_input":"2022-06-27T19:49:40.627675Z","iopub.status.idle":"2022-06-27T19:49:40.945996Z","shell.execute_reply.started":"2022-06-27T19:49:40.627621Z","shell.execute_reply":"2022-06-27T19:49:40.944783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"twitter_data.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2022-06-27T19:49:42.737199Z","iopub.execute_input":"2022-06-27T19:49:42.737704Z","iopub.status.idle":"2022-06-27T19:49:42.797705Z","shell.execute_reply.started":"2022-06-27T19:49:42.737663Z","shell.execute_reply":"2022-06-27T19:49:42.796171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Observation:\n* **The above barplot shows us that there are only three columns with missing values.**\n* **Percentage of missing values are also shown in the plot.**\n* **We can see that there is a lot of missing data in user_location, description. And very few user_name are missing.**","metadata":{}},{"cell_type":"markdown","source":"# Reasons for missing values!\n\n* **Sometimes a user doesnt add his/her description in the bio and also user make a tweet without any user_location !**\n* **But it's very strange of having missing value in user_name. I think it is a data collection error because no account can exist without user_name.**","metadata":{}},{"cell_type":"code","source":"#converting date column to date format\ntwitter_data['date'] = pd.to_datetime(twitter_data['date']).dt.date\ntwitter_data.head()\n","metadata":{"execution":{"iopub.status.busy":"2022-06-27T19:49:45.947804Z","iopub.execute_input":"2022-06-27T19:49:45.949163Z","iopub.status.idle":"2022-06-27T19:49:46.032102Z","shell.execute_reply.started":"2022-06-27T19:49:45.949106Z","shell.execute_reply":"2022-06-27T19:49:46.031096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Features exploration**","metadata":{}},{"cell_type":"markdown","source":"# **Most frequent values**","metadata":{}},{"cell_type":"code","source":"def most_frequent_values(data):\n    total = data.count()\n    tt = pd.DataFrame(total)\n    tt.columns = ['Total']\n    items = []\n    vals = []\n    for col in data.columns:\n        \n        itm = data[col].value_counts().index[0]\n        val = data[col].value_counts().values[0]\n        items.append(itm)\n        vals.append(val)\n    tt['Most frequent item'] = items\n    tt['Frequence'] = vals\n    tt['Percent from total'] = np.round(vals / total * 100, 3)\n    return(np.transpose(tt))","metadata":{"execution":{"iopub.status.busy":"2022-06-27T19:49:48.717907Z","iopub.execute_input":"2022-06-27T19:49:48.718603Z","iopub.status.idle":"2022-06-27T19:49:48.728708Z","shell.execute_reply.started":"2022-06-27T19:49:48.718547Z","shell.execute_reply":"2022-06-27T19:49:48.727574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"most_frequent_values(twitter_data)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T19:49:49.762809Z","iopub.execute_input":"2022-06-27T19:49:49.763341Z","iopub.status.idle":"2022-06-27T19:49:50.398135Z","shell.execute_reply.started":"2022-06-27T19:49:49.763296Z","shell.execute_reply":"2022-06-27T19:49:50.396972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Let's Look into the unique values**\n","metadata":{}},{"cell_type":"code","source":"def unique_values(data):\n    total = data.count()\n    tt = pd.DataFrame(total)\n    tt.columns = ['Total']\n    uniques = []\n    for col in data.columns:\n        unique = data[col].nunique()\n        uniques.append(unique)\n    tt['Uniques'] = uniques\n    tt['Percentage']=tt['Uniques']/tt['Total']\n    return(np.transpose(tt))","metadata":{"execution":{"iopub.status.busy":"2022-06-27T19:49:51.722421Z","iopub.execute_input":"2022-06-27T19:49:51.722876Z","iopub.status.idle":"2022-06-27T19:49:51.728773Z","shell.execute_reply.started":"2022-06-27T19:49:51.722835Z","shell.execute_reply":"2022-06-27T19:49:51.727581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unique_values(twitter_data)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T19:49:53.523691Z","iopub.execute_input":"2022-06-27T19:49:53.524751Z","iopub.status.idle":"2022-06-27T19:49:53.774178Z","shell.execute_reply.started":"2022-06-27T19:49:53.524707Z","shell.execute_reply":"2022-06-27T19:49:53.77302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Unique values in each column**","metadata":{}},{"cell_type":"code","source":"unique_df = pd.DataFrame()\nunique_df['Features'] = twitter_data.columns\nunique=[]\nfor i in twitter_data.columns:\n    unique.append(twitter_data[i].nunique())\nunique_df['Uniques'] = unique\n\nf, ax = plt.subplots(1,1, figsize=(15,7))\n\nsplot = sns.barplot(x=unique_df['Features'], y=unique_df['Uniques'], alpha=0.8)\nfor p in splot.patches:\n    splot.annotate(format(p.get_height(), '.0f'), (p.get_x() + p.get_width() / 2., p.get_height()), ha = 'center',\n                   va = 'center', xytext = (0, 9), textcoords = 'offset points')\nplt.title('Bar plot for number of unique values in each column',weight='bold', size=15)\nplt.ylabel('#Unique values', size=12, weight='bold')\nplt.xlabel('Features', size=12, weight='bold')\nplt.xticks(rotation=90)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-27T19:49:55.604144Z","iopub.execute_input":"2022-06-27T19:49:55.604651Z","iopub.status.idle":"2022-06-27T19:49:56.173658Z","shell.execute_reply.started":"2022-06-27T19:49:55.604609Z","shell.execute_reply":"2022-06-27T19:49:56.172452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Nearly 68% and 70% of the user name,and user description are unique**","metadata":{}},{"cell_type":"markdown","source":"# **Top50 users**","metadata":{}},{"cell_type":"code","source":"twitter_data_username_count = twitter_data['user_name'].value_counts().reset_index().rename(columns={\n    'user_name':'tweet_count','index':'user_name'})\n\nplt.figure(figsize=(15, 17))\nsns.barplot(y='user_name',x='tweet_count',data=twitter_data_username_count.head(50))\ny=twitter_data_username_count['tweet_count'].head(50)\nfor index, value in enumerate(y):\n    plt.text(value, index, str(value),fontsize=12)\nplt.title('Top50 users by number of tweets',weight='bold', size=15)\nplt.ylabel('User_name', size=12, weight='bold')\nplt.xlabel('Tweet_count', size=12, weight='bold')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-27T19:49:59.40684Z","iopub.execute_input":"2022-06-27T19:49:59.407382Z","iopub.status.idle":"2022-06-27T19:50:00.700639Z","shell.execute_reply.started":"2022-06-27T19:49:59.407335Z","shell.execute_reply":"2022-06-27T19:50:00.699329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Visulizing Tweet Count vs Location**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15,10))\ntwitter_data['user_location'].value_counts().nlargest(20).plot(kind='bar')\nplt.xticks(rotation=60)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T19:50:01.557853Z","iopub.execute_input":"2022-06-27T19:50:01.55874Z","iopub.status.idle":"2022-06-27T19:50:01.932483Z","shell.execute_reply.started":"2022-06-27T19:50:01.558678Z","shell.execute_reply":"2022-06-27T19:50:01.931338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Twitter tweets source distribution**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15,10))\ntwitter_data['source'].value_counts().nlargest(6).plot(kind='bar')\nplt.xticks(rotation=80)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T19:50:05.207466Z","iopub.execute_input":"2022-06-27T19:50:05.208188Z","iopub.status.idle":"2022-06-27T19:50:05.463847Z","shell.execute_reply.started":"2022-06-27T19:50:05.20813Z","shell.execute_reply":"2022-06-27T19:50:05.462693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Users created year by year**","metadata":{}},{"cell_type":"code","source":"twitter_data['Timestamp'] = pd.to_datetime(twitter_data.user_created, format=\"%d-%m-%Y %H:%M\", errors='coerce')\nmask = twitter_data.Timestamp.isnull()\ntwitter_data.loc[mask, 'Timestamp'] = pd.to_datetime(twitter_data[mask]['user_created'], format='%Y-%m-%d %H:%M:%S',\n                                             errors='coerce')\ntwitter_data['year_created'] = twitter_data['Timestamp'].dt.year\ndata = twitter_data.drop_duplicates(subset='user_name', keep=\"first\")\ndata = data[data['year_created']>1970]\ndata = data['year_created'].value_counts().reset_index()\ndata.columns = ['year', 'number']\n\nfig = sns.barplot( \n    x=data[\"year\"].astype(int), \n    y=data[\"number\"], \n    orientation='vertical'\n    #title='', \n).set_title('User created year by year')","metadata":{"execution":{"iopub.status.busy":"2022-06-27T19:50:07.904312Z","iopub.execute_input":"2022-06-27T19:50:07.904765Z","iopub.status.idle":"2022-06-27T19:50:08.406107Z","shell.execute_reply.started":"2022-06-27T19:50:07.904731Z","shell.execute_reply":"2022-06-27T19:50:08.404162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* **2021 has the highest number of users followed by the year 2009.**\n* **After 2009 it gradually decrease but from 2019 it increase exponential.**","metadata":{}},{"cell_type":"markdown","source":"# **Timestamp Analysis of tweets:**","metadata":{}},{"cell_type":"code","source":"twitter_data['tweet_date']=pd.to_datetime(twitter_data['date'],errors='coerce').dt.date\ntweet_date=twitter_data['tweet_date'].value_counts().to_frame().reset_index().rename(columns={'index':'date','tweet_date':'count'})\ntweet_date['date']=pd.to_datetime(tweet_date['date'])\ntweet_date=tweet_date.sort_values('date',ascending=False)\n\nfig=go.Figure(go.Scatter(x=tweet_date['date'],\n              y=tweet_date['count'],\n              mode='markers+lines',\n              name=\"Submissions\",\n              marker_color='dodgerblue'))\n\nfig.update_layout(\ntitle_text='Tweets per Day : ({} - {})'.format(twitter_data['tweet_date'].sort_values()[0]#.strftime(\"%d/%m/%Y\"),\n,twitter_data['tweet_date'].sort_values().iloc[-1]#.strftime(\"%d/%m/%Y\"))\n,template=\"plotly_dark\",title_x=0.5))\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-27T19:50:11.848698Z","iopub.execute_input":"2022-06-27T19:50:11.849765Z","iopub.status.idle":"2022-06-27T19:50:12.117656Z","shell.execute_reply.started":"2022-06-27T19:50:11.849714Z","shell.execute_reply":"2022-06-27T19:50:12.116397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stopwords = set(STOPWORDS)\n\ndef show_wordcloud(data, title = None):\n    wordcloud = WordCloud(\n        background_color='white',\n        stopwords=stopwords,\n        max_words=50,\n        max_font_size=40, \n        scale=5,\n        random_state=1\n    ).generate(str(data))\n\n    fig = plt.figure(1, figsize=(10,10))\n    plt.axis('off')\n    if title: \n        fig.suptitle(title, fontsize=20)\n        fig.subplots_adjust(top=2.3)\n\n    plt.imshow(wordcloud)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-27T19:50:12.980605Z","iopub.execute_input":"2022-06-27T19:50:12.981087Z","iopub.status.idle":"2022-06-27T19:50:12.98897Z","shell.execute_reply.started":"2022-06-27T19:50:12.981047Z","shell.execute_reply":"2022-06-27T19:50:12.987726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Text wordcloauds**","metadata":{}},{"cell_type":"code","source":"show_wordcloud(twitter_data['text'], title = 'Most frequent words in tweets')","metadata":{"execution":{"iopub.status.busy":"2022-06-27T19:50:14.828597Z","iopub.execute_input":"2022-06-27T19:50:14.829713Z","iopub.status.idle":"2022-06-27T19:50:15.707877Z","shell.execute_reply.started":"2022-06-27T19:50:14.829656Z","shell.execute_reply":"2022-06-27T19:50:15.705175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CA_df = twitter_data.loc[twitter_data.user_location==\"CA\"]\nshow_wordcloud(CA_df['text'], title = 'Most frequent words in tweets from CA ')","metadata":{"execution":{"iopub.status.busy":"2022-06-27T19:50:15.710087Z","iopub.execute_input":"2022-06-27T19:50:15.710519Z","iopub.status.idle":"2022-06-27T19:50:16.888275Z","shell.execute_reply.started":"2022-06-27T19:50:15.710482Z","shell.execute_reply":"2022-06-27T19:50:16.886952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"England_df =  twitter_data.loc[ twitter_data.user_location==\"England\"]\nshow_wordcloud(England_df['text'], title = 'Most frequent words in tweets from London, England')","metadata":{"execution":{"iopub.status.busy":"2022-06-27T19:50:21.222108Z","iopub.execute_input":"2022-06-27T19:50:21.223043Z","iopub.status.idle":"2022-06-27T19:50:22.166307Z","shell.execute_reply.started":"2022-06-27T19:50:21.222983Z","shell.execute_reply":"2022-06-27T19:50:22.164857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"us_df = twitter_data.loc[twitter_data.user_location==\"United States\"]\nshow_wordcloud(us_df['text'], title = 'Most frequent words in tweets from US')","metadata":{"execution":{"iopub.status.busy":"2022-06-27T19:50:23.633032Z","iopub.execute_input":"2022-06-27T19:50:23.633574Z","iopub.status.idle":"2022-06-27T19:50:24.552103Z","shell.execute_reply.started":"2022-06-27T19:50:23.633536Z","shell.execute_reply":"2022-06-27T19:50:24.55059Z"},"trusted":true},"execution_count":null,"outputs":[]}]}